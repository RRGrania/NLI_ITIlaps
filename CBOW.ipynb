{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18T0AJXMSwz-",
        "outputId": "cb20b49d-a013-42cf-a65d-495bcbb0582e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.0\n",
            "    Uninstalling numpy-1.23.0:\n",
            "      Successfully uninstalled numpy-1.23.0\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall numpy gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEG2P1VoSyrG",
        "outputId": "4c31ff33-b237-45d4-bf53-33960fccad8d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model['king']\n",
        "print(\"Vector shape:\", vector.shape)\n",
        "print(model.most_similar('king', topn=5))\n",
        "print(\"Sample vector values:\", vector[:10])\n",
        "similarity = model.similarity('king', 'queen')\n",
        "print(f\"Similarity between 'king' and 'queen': {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI2a-atjS9F2",
        "outputId": "34e27737-c715-41a4-87c4-7ab58677c8e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector shape: (100,)\n",
            "[('prince', 0.7682329416275024), ('queen', 0.7507690787315369), ('son', 0.7020888328552246), ('brother', 0.6985775828361511), ('monarch', 0.6977890729904175)]\n",
            "Sample vector values: [-0.32307 -0.87616  0.21977  0.25268  0.22976  0.7388  -0.37954 -0.35307\n",
            " -0.84369 -1.1113 ]\n",
            "Similarity between 'king' and 'queen': 0.7508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKF_P5O4Wvct",
        "outputId": "e5afc823-96af-4fd9-9e81-6ea39bca8034"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7698541283607483)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "context = ['queen', 'woman']\n",
        "context_vec = np.mean([model[word] for word in context], axis=0)\n",
        "\n",
        "similar_words = model.similar_by_vector(context_vec, topn=5)\n",
        "print(\"CBOW-style prediction:\", similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ7qmpN2W2KV",
        "outputId": "f52d3d71-c2ca-43e3-c672-bd84102d7af5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBOW-style prediction: [('queen', 0.8698275089263916), ('woman', 0.8677042722702026), ('mother', 0.8308935165405273), ('girl', 0.7884058356285095), ('wife', 0.7862660884857178)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_word(context):\n",
        "    context_vec = np.mean([model[word] for word in context if word in model], axis=0)\n",
        "    similar_words = model.similar_by_vector(context_vec, topn=5)\n",
        "    return similar_words\n",
        "\n",
        "contexts = [\n",
        "    ['king', 'woman'],\n",
        "    ['paris', 'france'],\n",
        "    ['man', 'computer'],\n",
        "    ['river', 'water'],\n",
        "    ['queen', 'throne']\n",
        "]\n",
        "\n",
        "for context in contexts:\n",
        "    prediction = predict_word(context)\n",
        "    print(f\"Context: {context}\")\n",
        "    for word, similarity in prediction:\n",
        "        print(f\"  → {word} (similarity: {similarity:.4f})\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmhezAPfXNu7",
        "outputId": "7271b4ec-8c1d-459c-ff47-e5560d6add7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['king', 'woman']\n",
            "  → king (similarity: 0.8313)\n",
            "  → woman (similarity: 0.8214)\n",
            "  → father (similarity: 0.8200)\n",
            "  → mother (similarity: 0.8111)\n",
            "  → man (similarity: 0.8108)\n",
            "\n",
            "Context: ['paris', 'france']\n",
            "  → france (similarity: 0.9393)\n",
            "  → paris (similarity: 0.9304)\n",
            "  → french (similarity: 0.8006)\n",
            "  → prohertrib (similarity: 0.7475)\n",
            "  → belgium (similarity: 0.7254)\n",
            "\n",
            "Context: ['man', 'computer']\n",
            "  → computer (similarity: 0.8561)\n",
            "  → man (similarity: 0.7975)\n",
            "  → one (similarity: 0.7449)\n",
            "  → turned (similarity: 0.7364)\n",
            "  → another (similarity: 0.7187)\n",
            "\n",
            "Context: ['river', 'water']\n",
            "  → river (similarity: 0.9115)\n",
            "  → water (similarity: 0.8940)\n",
            "  → rivers (similarity: 0.7984)\n",
            "  → lake (similarity: 0.7621)\n",
            "  → reservoir (similarity: 0.7338)\n",
            "\n",
            "Context: ['queen', 'throne']\n",
            "  → queen (similarity: 0.9042)\n",
            "  → throne (similarity: 0.9017)\n",
            "  → king (similarity: 0.7991)\n",
            "  → monarch (similarity: 0.7438)\n",
            "  → crown (similarity: 0.7422)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ci_78YBvYx2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}